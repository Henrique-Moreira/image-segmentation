{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guia de Estudo: Compreendendo a Arquitetura VGG_UNET\n",
    "## Questionário\n",
    "1) Qual a função principal do arquivo VGG_UNET.py?\n",
    "2) Descreva a relação entre os arquivos train.py e data_utils.py no processo de treinamento da rede neural.\n",
    "3) O que se pode esperar encontrar no arquivo inference_sample.py?\n",
    "4) Com base nos nomes dos arquivos, qual a arquitetura de rede neural utilizada neste projeto? Descreva suas características principais.\n",
    "5) Para que serve a arquitetura UNET em aplicações de aprendizado de máquina? Cite exemplos de áreas onde ela se destaca.\n",
    "6) Explique a importância do processo de treinamento em uma rede neural. Como ele se relaciona com os arquivos mencionados?\n",
    "7) O que são dados de treinamento e como o arquivo data_utils.py pode auxiliar nesse processo?\n",
    "8) Deduza a partir dos nomes dos arquivos qual a linguagem de programação utilizada neste projeto. Justifique sua resposta.\n",
    "9) Qual a provável finalidade do arquivo readme.md no contexto deste projeto?\n",
    "10) Imagine que você precisa modificar o conjunto de dados utilizado no treinamento. Qual arquivo você precisaria editar? Por quê?\n",
    "\n",
    "## Gabarito\n",
    "- O arquivo VGG_UNET.py define a arquitetura da rede neural, especificando as camadas, funções de ativação e outros parâmetros do modelo.\n",
    "- O arquivo train.py é responsável por executar o processo de treinamento da rede neural, utilizando os dados preparados pelo arquivo data_utils.py.\n",
    "- O arquivo inference_sample.py provavelmente contém um exemplo de como utilizar a rede neural treinada para realizar inferências em novos dados.\n",
    "- A arquitetura utilizada é a VGG_UNET, uma combinação da rede VGG (rede convolucional profunda) com a arquitetura UNET (eficiente para segmentação de imagens).\n",
    "- A arquitetura UNET é comumente utilizada para tarefas de segmentação de imagens, como em imagens médicas, detecção de objetos e processamento de imagens de satélite.\n",
    "- O treinamento é a etapa onde a rede neural \"aprende\" a partir dos dados fornecidos, ajustando seus parâmetros para realizar a tarefa desejada. O arquivo train.py executa o processo, utilizando a arquitetura definida em VGG_UNET.py e os dados preparados por data_utils.py.\n",
    "- Dados de treinamento são o conjunto de exemplos utilizados para treinar a rede neural. O arquivo data_utils.py auxilia no processamento, organização e carregamento desses dados para o treinamento.\n",
    "- A linguagem de programação utilizada é provavelmente Python, visto que a extensão \".py\" é comumente associada a arquivos de código Python.\n",
    "- O arquivo readme.md serve como um guia introdutório ao projeto, contendo informações sobre os arquivos, como utilizá-los e outras informações relevantes.\n",
    "- Para modificar o conjunto de dados, seria necessário editar o arquivo data_utils.py, pois ele é responsável por carregar e preparar os dados para o treinamento.\n",
    "  \n",
    "## Questões para Dissertação\n",
    "- Discuta as vantagens e desvantagens de utilizar a arquitetura VGG_UNET em comparação com outras arquiteturas de redes neurais para tarefas de segmentação de imagens.\n",
    "- Explique em detalhes como o processo de treinamento da rede neural é realizado no contexto dos arquivos mencionados. Quais parâmetros são ajustados e como o desempenho da rede é avaliado?\n",
    "- Descreva o papel das funções de ativação em uma rede neural e discuta a importância da escolha adequada dessas funções para o sucesso do treinamento.\n",
    "- Com base nos nomes dos arquivos, especule sobre o tipo de dados que este projeto utiliza para treinamento e inferência. Que tipo de pré-processamento de dados pode ser necessário para preparar os dados para a rede neural?\n",
    "- Imagine que você precisa integrar este projeto a um sistema maior. Descreva como você faria a interface entre a rede neural treinada e outros componentes do sistema, considerando os arquivos mencionados.\n",
    "## Glossário\n",
    "- VGG_UNET: Arquitetura de rede neural que combina a rede VGG com a arquitetura UNET, geralmente utilizada para segmentação de imagens.\n",
    "- Rede Neural: Modelo computacional inspirado no cérebro humano, capaz de aprender a partir de dados e realizar tarefas como classificação, regressão e segmentação.\n",
    "- Treinamento: Processo de ajuste dos parâmetros da rede neural para que ela aprenda a realizar a tarefa desejada.\n",
    "- Dados de Treinamento: Conjunto de dados utilizado para treinar a rede neural.\n",
    "- Inferência: Processo de utilizar a rede neural treinada para realizar predições em novos dados.\n",
    "- Segmentação de Imagens: Tarefa de dividir uma imagem em diferentes regiões, cada uma representando um objeto ou classe diferente.\n",
    "- Função de Ativação: Função matemática que introduz não-linearidade na rede neural, permitindo que ela aprenda relações complexas nos dados.\n",
    "- Python: Linguagem de programação popularmente utilizada em projetos de aprendizado de máquina e ciência de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalação de Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install torch\n",
    "%pip install torchvision\n",
    "%pip install utils2\n",
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importe os módulos necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "import cv2\n",
    "import torch\n",
    "import os.path as osp\n",
    "import glob\n",
    "import torchvision\n",
    "\n",
    "# Train\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Inference\n",
    "import os.path as osp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaração de Variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# CUDA:\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f'CUDA disponível: {cuda_available}')\n",
    "\n",
    "if cuda_available:\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    vram_total = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)  # Convertendo para GB\n",
    "    vram_available = torch.cuda.memory_reserved(0) / (1024 ** 3)  # Convertendo para GB\n",
    "    print(f'Nome da GPU: {gpu_name}')\n",
    "    print(f'VRAM Total: {vram_total:.2f} GB')\n",
    "\n",
    "# Caminho do diretório Dataset:\n",
    "directory = os.path.abspath(os.path.join(os.getcwd(), '..')) + r'\\dataset\\trigo'\n",
    "print(f'Diretório do Projeto {directory}.')\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "img_folder_val = directory + r'\\Val'\n",
    "img_folder_train = directory + r'\\Train'\n",
    "img_folder_test = directory + r'\\Test'\n",
    "save_dir = directory + r'\\\\result_psp\\\\'\n",
    "if not os.path.exists(img_folder_val):\n",
    "    os.makedirs(img_folder_val)\n",
    "if not os.path.exists(img_folder_train):\n",
    "    os.makedirs(img_folder_train)\n",
    "if not os.path.exists(img_folder_test):\n",
    "    os.makedirs(img_folder_test)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# Local onde o Modelo será salvo\n",
    "model_file_name = save_dir + 'model_unet.pth'\n",
    "\n",
    "# size mismatch (got input: [1, 3, 480, 640] , target: [1, 960, 1280]\n",
    "resolution_input = (640, 480) # Size Out (1280, 960)\n",
    "\n",
    "patience = 30\n",
    "plot_val = True\n",
    "plot_train = True\n",
    "\n",
    "max_epochs = 100\n",
    "\n",
    "#Width x Height - MUST be divisible by 32\n",
    "class_weights = [1, 1, 1]\n",
    "nClasses = 3\n",
    "\n",
    "# Color in RGB\n",
    "class_to_color = {'wheat': (127, 0, 0)}\n",
    "class_to_id = {'wheat': 0}\n",
    "id_to_class = {v: k for k, v in class_to_id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase para Segmentação de Dataset\n",
    "\n",
    "    Este arquivo provavelmente contém funções utilitárias para manipular e preparar os dados para o treinamento do modelo. As utilidades de dados aqui podem incluir:\n",
    "        - Carregamento de dados de diferentes fontes (arquivos, bancos de dados, APIs).\n",
    "        - Limpeza e pré-processamento de dados (por exemplo, lidar com valores ausentes, normalização, conversão de tipos de dados).\n",
    "        - Aumento de dados para aumentar o tamanho do conjunto de dados de treinamento.\n",
    "        - Divisão dos dados em conjuntos de treinamento, validação e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    \"\"\"Segmentation dataset loader.\"\"\"\n",
    "\n",
    "    def __init__(self, json_folder, img_folder, is_train, class_to_id, resolution_input=(640, 480), augmentation=False, transform=None):\n",
    "        self.gt_file_list = glob.glob(osp.join(json_folder, '*.json'))\n",
    "        self.total_samples = len(self.gt_file_list)\n",
    "        self.img_folder = img_folder\n",
    "        self.is_train = is_train\n",
    "        self.transform = transform\n",
    "        self.augmentation = augmentation\n",
    "        self.resolution = resolution_input\n",
    "        self.class_to_id = class_to_id\n",
    "        self.mean = [0.485, 0.456, 0.406]\n",
    "        self.std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gt_file = self.gt_file_list[idx]\n",
    "        img_number_str = gt_file.split('.')[0].split('/')[-1]\n",
    "        gt_json = json.load(open(gt_file, 'r'))\n",
    "        img_np = cv2.imread(osp.join(self.img_folder, img_number_str + '.jpg'), cv2.IMREAD_IGNORE_ORIENTATION + cv2.IMREAD_COLOR)\n",
    "        \n",
    "        if img_np is None:\n",
    "            raise FileNotFoundError(f\"Imagem não encontrada: {osp.join(self.img_folder, img_number_str + '.jpg')}\")\n",
    "        \n",
    "        original_shape = img_np.shape\n",
    "        img_np = cv2.resize(img_np, (self.resolution[0], self.resolution[1]))[..., ::-1]\n",
    "        img_np = np.ascontiguousarray(img_np)\n",
    "        label_np = np.zeros((img_np.shape[0], img_np.shape[1]))\n",
    "        label_np[...] = -1\n",
    "\n",
    "        for shape in gt_json['shapes']:\n",
    "            points_np = np.array(shape['points'], dtype=np.float64)\n",
    "            points_np[:, 0] *= self.resolution[0] / original_shape[1]\n",
    "            points_np[:, 1] *= self.resolution[1] / original_shape[0]\n",
    "            points_np = np.round(points_np).astype(np.int64)\n",
    "            points_np = points_np.reshape((-1, 1, 2))\n",
    "            label_np = cv2.fillPoly(label_np, [points_np], self.class_to_id[shape['label']])\n",
    "\n",
    "        label_np = label_np.astype(np.int32)\n",
    "\n",
    "        if self.is_train and self.augmentation:\n",
    "            if np.random.rand() > 0.5:\n",
    "                img_np = np.fliplr(img_np)\n",
    "                label_np = np.fliplr(label_np)\n",
    "                img_np = np.ascontiguousarray(img_np)\n",
    "                label_np = np.ascontiguousarray(label_np)\n",
    "\n",
    "        img_pt = img_np.astype(np.float32) / 255.0\n",
    "        for i in range(3):\n",
    "            img_pt[..., i] -= self.mean[i]\n",
    "            img_pt[..., i] /= self.std[i]\n",
    "\n",
    "        img_pt = img_pt.transpose(2, 0, 1)\n",
    "        img_pt = torch.from_numpy(img_pt)\n",
    "        label_pt = torch.from_numpy(label_np).long()\n",
    "\n",
    "        sample = {'image': img_pt, 'gt': label_pt, 'image_original': img_np}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG_UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetVgg(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    BorderNetwork is a NN that aims to detected border and classify occlusion.\n",
    "    The architecture is a VGG without the last pool layer. After that we \n",
    "    have two paths, one for regression and one for classification (occlusion).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, nClasses):\n",
    "        super(UNetVgg, self).__init__()\n",
    "        \n",
    "        vgg16pre = torchvision.models.vgg16(pretrained=True)\n",
    "        self.vgg0 = torch.nn.Sequential(*list(vgg16pre.features.children())[:4])\n",
    "        self.vgg1 = torch.nn.Sequential(*list(vgg16pre.features.children())[4:9])\n",
    "        self.vgg2 = torch.nn.Sequential(*list(vgg16pre.features.children())[9:16])\n",
    "        self.vgg3 = torch.nn.Sequential(*list(vgg16pre.features.children())[16:23])\n",
    "        self.vgg4 = torch.nn.Sequential(*list(vgg16pre.features.children())[23:30])\n",
    "        \n",
    "        \n",
    "        self.smooth0 = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(128, 64, kernel_size=(3,3), stride=1, padding=(1, 1)),\n",
    "                torch.nn.ReLU(True),\n",
    "                torch.nn.Conv2d(64, 64, kernel_size=(3,3), stride=1, padding=(1, 1)),\n",
    "                torch.nn.ReLU(True)\n",
    "                )\n",
    "        self.smooth1 = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(256, 64, kernel_size=(3,3), stride=1, padding=(1, 1)),\n",
    "                torch.nn.ReLU(True),\n",
    "                torch.nn.Conv2d(64, 64, kernel_size=(3,3), stride=1, padding=(1, 1)),\n",
    "                torch.nn.ReLU(True)\n",
    "                )\n",
    "        self.smooth2 = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(512, 128, kernel_size=(3,3), stride=1, padding=(1, 1)),\n",
    "                torch.nn.ReLU(True),\n",
    "                torch.nn.Conv2d(128, 128, kernel_size=(3,3), stride=1, padding=(1, 1)),\n",
    "                torch.nn.ReLU(True)\n",
    "                )\n",
    "        self.smooth3 = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(1024, 256, kernel_size=(3,3), stride=1, padding=(1, 1)),\n",
    "                torch.nn.ReLU(True),\n",
    "                torch.nn.Conv2d(256, 256, kernel_size=(3,3), stride=1, padding=(1, 1)),\n",
    "                torch.nn.ReLU(True)\n",
    "                )\n",
    "        \n",
    "        \n",
    "        self.final = torch.nn.Conv2d(64, nClasses, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (torch.tensor): A tensor of size (batch, 3, H, W)\n",
    "        Returns:\n",
    "            reg_out (torch.tensor): A tensor with results of the regression (batch, 4).\n",
    "            cls_out (torch.tensor): A tensor with results of the classification (batch, 2).\n",
    "        \"\"\"\n",
    "        \n",
    "        feat0 = self.vgg0(x)\n",
    "        feat1 = self.vgg1(feat0)\n",
    "        feat2 = self.vgg2(feat1)\n",
    "        feat3 = self.vgg3(feat2)\n",
    "        feat4 = self.vgg4(feat3)\n",
    "        \n",
    "        _,_,H,W = feat3.size()\n",
    "        up3 = torch.nn.functional.interpolate(feat4, size=(H,W), mode='bilinear', align_corners=False)\n",
    "        concat3 = torch.cat([feat3, up3], 1)\n",
    "        end3 = self.smooth3(concat3)\n",
    "        \n",
    "        _,_,H,W = feat2.size()\n",
    "        up2 = torch.nn.functional.interpolate(end3, size=(H,W), mode='bilinear', align_corners=False)\n",
    "        concat2 = torch.cat([feat2, up2], 1)\n",
    "        end2 = self.smooth2(concat2)\n",
    "        \n",
    "        _,_,H,W = feat1.size()\n",
    "        up1 = torch.nn.functional.interpolate(end2, size=(H,W), mode='bilinear', align_corners=False)\n",
    "        concat1 = torch.cat([feat1, up1], 1)\n",
    "        end1 = self.smooth1(concat1)\n",
    "        \n",
    "        _,_,H,W = feat0.size()\n",
    "        up0 = torch.nn.functional.interpolate(end1, size=(H,W), mode='bilinear', align_corners=False)\n",
    "        concat0 = torch.cat([feat0, up0], 1)\n",
    "        end0 = self.smooth0(concat0)\n",
    "        \n",
    "        return self.final(end0)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def eval_net_with_loss(model, inp, gt, class_weights, device):\n",
    "        \"\"\"\n",
    "        Evaluate network including loss.\n",
    "        \n",
    "        Args:\n",
    "            model (torch.nn.Module): The model.\n",
    "            inp (torch.tensor): A tensor (float32) of size (batch, 3, H, W)\n",
    "            gt (torch.tensor): A tensor (long) of size (batch, 1, H, W) with the groud truth (0 to num_classes-1).\n",
    "            class_weights (list of float): A list with len == num_classes.\n",
    "            device (torch.device): device to perform computation\n",
    "            \n",
    "        Returns:\n",
    "            out (torch.tensor): Network output.\n",
    "            loss (torch.tensor): Tensor with the total loss.\n",
    "                \n",
    "        \"\"\"\n",
    "        weights = torch.from_numpy(np.array(class_weights, dtype=np.float32)).to(device)\n",
    "        out = model(inp)\n",
    "        \n",
    "        softmax = torch.nn.functional.log_softmax(out, dim = 1)\n",
    "        loss = torch.nn.functional.nll_loss(softmax, gt, ignore_index=-1, weight=weights)\n",
    "            \n",
    "        return (out, loss)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_params_by_kind(model, n_base = 7):\n",
    "    \n",
    "        base_vgg_bias = []\n",
    "        base_vgg_weight = []\n",
    "        core_weight = []\n",
    "        core_bias = []\n",
    "    \n",
    "        for name, param in model.named_parameters():\n",
    "            if 'vgg' in name and ('weight' in name or 'bias' in name):\n",
    "                vgglayer = int(name.split('.')[-2])\n",
    "                \n",
    "                if vgglayer <= n_base:\n",
    "                    if 'bias' in name:\n",
    "                        print('Adding %s to base vgg bias.' % (name))\n",
    "                        base_vgg_bias.append(param)\n",
    "                    else:\n",
    "                        base_vgg_weight.append(param)\n",
    "                        print('Adding %s to base vgg weight.' % (name))\n",
    "                else:\n",
    "                    if 'bias' in name:\n",
    "                        print('Adding %s to core bias.' % (name))\n",
    "                        core_bias.append(param)\n",
    "                    else:\n",
    "                        print('Adding %s to core weight.' % (name))\n",
    "                        core_weight.append(param)\n",
    "                        \n",
    "            elif ('weight' in name or 'bias' in name):\n",
    "                if 'bias' in name:\n",
    "                    print('Adding %s to core bias.' % (name))\n",
    "                    core_bias.append(param)\n",
    "                else:\n",
    "                    print('Adding %s to core weight.' % (name))\n",
    "                    core_weight.append(param)\n",
    "                    \n",
    "        return (base_vgg_weight, base_vgg_bias, core_weight, core_bias)\n",
    "    \n",
    "# End class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realiza o Treinamento da Rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar listas para armazenar a perda e a precisão\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Inicia o treinamento\n",
    "train_dataset = SegmentationDataset(img_folder_train, img_folder_train, True, class_to_id, resolution_input, True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=0, drop_last=True)\n",
    "\n",
    "val_dataset = SegmentationDataset(img_folder_val, img_folder_val, False, class_to_id, resolution_input)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True, num_workers=0, drop_last=False)\n",
    "\n",
    "\n",
    "if plot_train:\n",
    "\n",
    "    for i_batch, sample_batched in enumerate(train_loader):\n",
    "    \n",
    "            image_np = np.squeeze(sample_batched['image_original'].cpu().numpy())\n",
    "            gt = np.squeeze(sample_batched['gt'].cpu().numpy())\n",
    "                \n",
    "            color_label = np.zeros((resolution_input[1], resolution_input[0], 3))\n",
    "            \n",
    "            for key, val in id_to_class.items():\n",
    "                color_label[gt == key] = class_to_color[val]\n",
    "                \n",
    "            plt.figure()\n",
    "            plt.imshow((image_np/255) * 0.5 + (color_label/255) * 0.5)\n",
    "            plt.show()\n",
    "            \n",
    "            plt.figure()\n",
    "            plt.imshow(color_label.astype(np.uint8))\n",
    "            plt.show()\n",
    "\n",
    "  \n",
    "model = UNetVgg(nClasses).to(device)\n",
    "\n",
    "core_lr = 0.02\n",
    "base_vgg_weight, base_vgg_bias, core_weight, core_bias = UNetVgg.get_params_by_kind(model, 7)\n",
    "\n",
    "optimizer = torch.optim.SGD([{'params': base_vgg_bias, 'lr': 0.000001}, \n",
    "                             {'params': base_vgg_weight, 'lr': 0.000001},\n",
    "                             {'params': core_bias, 'lr': core_lr},\n",
    "                             {'params': core_weight, 'lr': core_lr, 'weight_decay': 0.0005}], momentum=0.9)\n",
    "    \n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 30, gamma=0.2)\n",
    "\n",
    "\n",
    "best_val_acc = -1\n",
    "best_epoch = 0\n",
    "\n",
    "# Start training...\n",
    "for epoch in range(max_epochs):\n",
    "    \n",
    "    print('Epoch %d starting...' % (epoch+1))\n",
    "    \n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    mean_loss = 0.0\n",
    "    \n",
    "    n_correct = 0\n",
    "    n_false = 0\n",
    "    \n",
    "    for i_batch, sample_batched in enumerate(train_loader):\n",
    "    \n",
    "    \n",
    "        image = sample_batched['image'].to(device)\n",
    "        gt = sample_batched['gt'].to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        output, total_loss = model.eval_net_with_loss(model, image, gt, class_weights, device)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        mean_loss += total_loss.cpu().detach().numpy()\n",
    "        \n",
    "        # Measure accuracy\n",
    "        \n",
    "        gt = np.squeeze(sample_batched['gt'].cpu().numpy())\n",
    "        \n",
    "        label_out = torch.nn.functional.softmax(output, dim = 1)\n",
    "        label_out = label_out.cpu().detach().numpy()\n",
    "        label_out = np.squeeze(label_out)\n",
    "        \n",
    "        labels = np.argmax(label_out, axis=0)\n",
    "        valid_mask = gt != -1\n",
    "        curr_correct = np.sum(gt[valid_mask] == labels[valid_mask])\n",
    "        curr_false = np.sum(valid_mask) - curr_correct\n",
    "        n_correct += curr_correct\n",
    "        n_false += curr_false\n",
    "        \n",
    "    mean_loss /= len(train_loader)\n",
    "    train_acc = n_correct / (n_correct + n_false)\n",
    "        \n",
    "    print('Train loss: %f, train acc: %f' % (mean_loss, train_acc))\n",
    "    # Armazenar a perda e a precisão de treinamento\n",
    "    train_losses.append(mean_loss)\n",
    "    train_accuracies.append(train_acc)    \n",
    "    \n",
    "    n_correct = 0\n",
    "    n_false = 0\n",
    "    \n",
    "    \n",
    "    for i_batch, sample_batched in enumerate(val_loader):\n",
    "    \n",
    "    \n",
    "        image = sample_batched['image'].to(device)\n",
    "        image_np = np.squeeze(sample_batched['image_original'].cpu().numpy())\n",
    "        gt = np.squeeze(sample_batched['gt'].cpu().numpy())\n",
    "        \n",
    "    \n",
    "        label_out = model(image)\n",
    "        label_out = torch.nn.functional.softmax(label_out, dim = 1)\n",
    "        label_out = label_out.cpu().detach().numpy()\n",
    "        label_out = np.squeeze(label_out)\n",
    "        \n",
    "        labels = np.argmax(label_out, axis=0)\n",
    "        \n",
    "        if plot_val:\n",
    "            \n",
    "            color_label = np.zeros((resolution_input[1], resolution_input[0], 3))\n",
    "            \n",
    "            for key, val in id_to_class.items():\n",
    "                color_label[labels == key] = class_to_color[val]\n",
    "                \n",
    "            plt.figure()\n",
    "            plt.imshow((image_np/255) * 0.5 + (color_label/255) * 0.5)\n",
    "            plt.show()\n",
    "            \n",
    "            plt.figure()\n",
    "            plt.imshow(color_label.astype(np.uint8))\n",
    "            plt.show()\n",
    "        \n",
    "        valid_mask = gt != -1\n",
    "        curr_correct = np.sum(gt[valid_mask] == labels[valid_mask])\n",
    "        curr_false = np.sum(valid_mask) - curr_correct\n",
    "        n_correct += curr_correct\n",
    "        n_false += curr_false    \n",
    "        \n",
    "    total_acc = n_correct / (n_correct + n_false)\n",
    "    val_accuracies.append(total_acc)\n",
    "    \n",
    "    if best_val_acc < total_acc:\n",
    "        best_val_acc = total_acc\n",
    "        if epoch > 7:\n",
    "            torch.save(model.state_dict(), model_file_name)\n",
    "            print('Nova melhor conta de validação. Salvo... %f', epoch)\n",
    "        best_epoch = epoch\n",
    "\n",
    "    if (epoch - best_epoch) > patience:\n",
    "        print(f\"Terminando o treinamento, melhor conta de validação {best_val_acc:.6f}\")\n",
    "        break\n",
    "    \n",
    "    print('Validação Acc: %f -- Melhor Avaliação Acc: %f -- epoch %d.' % (total_acc, best_val_acc, best_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotar os gráficos de perda e precisão\n",
    "    Inicialização das listas: train_losses, train_accuracies e val_accuracies são listas para armazenar a perda e a precisão de treinamento e validação em cada época.\n",
    "    \n",
    "    Armazenamento dos valores: Durante o loop de treinamento, a perda e a precisão são calculadas e armazenadas nas listas correspondentes.\n",
    "    Plotagem dos gráficos: Após o loop de treinamento, os gráficos de perda e precisão são plotados usando matplotlib.\n",
    "\n",
    "Este código deve ser adicionado ao final do seu loop de treinamento no notebook para visualizar os resultados do treinamento ao longo das épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Perda de Treinamento')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Perda')\n",
    "plt.title('Perda de Treinamento ao longo das Épocas')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(train_accuracies) + 1), train_accuracies, label='Precisão de Treinamento')\n",
    "plt.plot(range(1, len(val_accuracies) + 1), val_accuracies, label='Precisão de Validação')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Precisão')\n",
    "plt.title('Precisão de Treinamento e Validação ao longo das Épocas')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferência de dados\n",
    "Processo de usar um modelo treinado para fazer previsões sobre novos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color in RGB\n",
    "class_to_color = {'wheat': (127, 0, 0)}\n",
    "class_to_id = {'wheat': 0}\n",
    "id_to_class = {v: k for k, v in class_to_id.items()}\n",
    "nClasses = 3\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "model = UNetVgg(nClasses)\n",
    "model.load_state_dict(torch.load(model_file_name))\n",
    "model.eval()\n",
    "print(\"Modelo carregado e pronto para uso.\")\n",
    "model.to(device)\n",
    "\n",
    "img_list = glob.glob(osp.join(img_folder_val, '*.jpg'))\n",
    "\n",
    "for img_path in img_list:\n",
    "\n",
    "        img_np = cv2.imread(img_path, cv2.IMREAD_IGNORE_ORIENTATION + cv2.IMREAD_COLOR)\n",
    "        img_np = cv2.resize(img_np, (resolution_input[0], resolution_input[1]))[..., ::-1]\n",
    "        img_np = np.ascontiguousarray(img_np)\n",
    "        \n",
    "        img_pt = np.copy(img_np).astype(np.float32) / 255.0\n",
    "        for i in range(3):\n",
    "            img_pt[..., i] -= mean[i]\n",
    "            img_pt[..., i] /= std[i]\n",
    "            \n",
    "        img_pt = img_pt.transpose(2,0,1)\n",
    "            \n",
    "        img_pt = torch.from_numpy(img_pt[None, ...]).to(device)\n",
    "        \n",
    "        label_out = model(img_pt)\n",
    "        label_out = torch.nn.functional.softmax(label_out, dim = 1)\n",
    "        label_out = label_out.cpu().detach().numpy()\n",
    "        label_out = np.squeeze(label_out)\n",
    "        \n",
    "        labels = np.argmax(label_out, axis=0)\n",
    "        \n",
    "        color_label = np.zeros((resolution_input[1], resolution_input[0], 3))\n",
    "            \n",
    "        for key, val in id_to_class.items():\n",
    "            color_label[labels == key] = class_to_color[val]\n",
    "            \n",
    "        plt.figure()\n",
    "        plt.imshow((img_np/255) * 0.5 + (color_label/255) * 0.5)\n",
    "        plt.savefig(save_dir + \"IMG\" + \".png\")\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.imshow(color_label.astype(np.uint8))\n",
    "        plt.savefig(save_dir + \"GT\" + \".png\")\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
