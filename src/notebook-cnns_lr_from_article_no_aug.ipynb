{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar as bibliotecas necessárias\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Verificar se CUDA está disponível e definir o dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Usando o dispositivo: {device}\")\n",
    "\n",
    "# Definir as cores para as classes\n",
    "CLASS_COLORS = { \n",
    "    'Doenca': (255, 0, 0), \n",
    "    'Saudavel': (0, 255, 0), \n",
    "    'Solo': (0, 0, 255),\n",
    "    'Fundo': (0, 0, 0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definicao dos hiperparametros.\n",
    "criterion = nn.CrossEntropyLoss()  # Considerando que temos múltiplas classes\n",
    "# learning_rate = 0.001\n",
    "num_epochs = 300\n",
    "patience = 30\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe do Dataset personalizado\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(image_dir)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        \n",
    "        # Modificar a extensão da máscara para '.png'\n",
    "        mask_name = os.path.splitext(img_name)[0] + '.png'\n",
    "        mask_path = os.path.join(self.mask_dir, mask_name)\n",
    "        \n",
    "        # Carregar a imagem e a máscara\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            # Aplicar transformações, se houver\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "            \n",
    "        # Convertemos as máscaras de imagem em um array de índices de classe\n",
    "        mask = self.mask_to_class(mask)\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def mask_to_class(self, mask):\n",
    "        # Converte a máscara para um array NumPy e ajusta para escala de 0 a 255\n",
    "        mask_array = (np.array(mask, dtype=np.float32) * 255).astype(np.uint8)\n",
    "\n",
    "        # Garantir que esté em [H, W, C]\n",
    "        if mask_array.shape[0] == 3:\n",
    "            mask_array = mask_array.transpose(1, 2, 0)\n",
    "\n",
    "        mask_indices = np.zeros((mask_array.shape[0], mask_array.shape[1]), dtype=np.int64)\n",
    "\n",
    "        for i, color in enumerate(CLASS_COLORS.values()):\n",
    "            # Realizar comparação e detecção de igualdade entre pixels\n",
    "            equal_color = np.all(mask_array == color, axis=-1)\n",
    "            mask_indices[equal_color] = i\n",
    "\n",
    "        return torch.tensor(mask_indices, dtype=torch.long)\n",
    "\n",
    "# Função para criar transformações de dados normais e de aumento de dados\n",
    "def get_transforms():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((256, 256)),  # Redimensiona para uma dimensão adequada para o modelo\n",
    "        transforms.ToTensor(),  # Normaliza para [0, 1]\n",
    "    ])\n",
    "\n",
    "# Outras inicializações de datasets e dataloaders\n",
    "train_dataset = SegmentationDataset(\n",
    "    image_dir=\"E:/Mestrado/Materias/2024-02-Sistemas para Processamento Multimidia/seminario/image-segmentation/dataset/base-no-aug/Train\",\n",
    "    mask_dir=\"E:/Mestrado/Materias/2024-02-Sistemas para Processamento Multimidia/seminario/image-segmentation/dataset/masks-no-aug/Train\",\n",
    "    transform=get_transforms()\n",
    ")\n",
    "\n",
    "val_dataset = SegmentationDataset(\n",
    "    image_dir=\"E:/Mestrado/Materias/2024-02-Sistemas para Processamento Multimidia/seminario/image-segmentation/dataset/base-no-aug/Val\",\n",
    "    mask_dir=\"E:/Mestrado/Materias/2024-02-Sistemas para Processamento Multimidia/seminario/image-segmentation/dataset/masks-no-aug/Val\",\n",
    "    transform=get_transforms()\n",
    ")\n",
    "\n",
    "test_dataset = SegmentationDataset(\n",
    "    image_dir=\"E:/Mestrado/Materias/2024-02-Sistemas para Processamento Multimidia/seminario/image-segmentation/dataset/base-no-aug/Test\",\n",
    "    mask_dir=\"E:/Mestrado/Materias/2024-02-Sistemas para Processamento Multimidia/seminario/image-segmentation/dataset/masks-no-aug/Test\",\n",
    "    transform=get_transforms()\n",
    ")\n",
    "# Criar os DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"Dados carregados e preparados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar a biblioteca segmentation-models-pytorch\n",
    "!pip install segmentation-models-pytorch --quiet\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# Inicializar as arquiteturas dos modelos com os pesos pretreinados por padrão\n",
    "unet = smp.Unet(encoder_name='resnet34', encoder_weights='imagenet', in_channels=3, classes=len(CLASS_COLORS)).to(device)\n",
    "pspnet = smp.PSPNet(encoder_name='resnet34', encoder_weights='imagenet', in_channels=3, classes=len(CLASS_COLORS)).to(device)\n",
    "linknet = smp.Linknet(encoder_name='resnet34', encoder_weights='imagenet', in_channels=3, classes=len(CLASS_COLORS)).to(device)\n",
    "deeplabv3 = smp.DeepLabV3(encoder_name='resnet34', encoder_weights='imagenet', in_channels=3, classes=len(CLASS_COLORS)).to(device)\n",
    "\n",
    "models = {\n",
    "    'U-Net': unet,\n",
    "    'PSPNet': pspnet,\n",
    "    'LinkNet': linknet\n",
    "}\n",
    "\n",
    "print(\"Modelos configurados e prontos para treinamento.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "from torchmetrics.classification import MulticlassJaccardIndex, MulticlassF1Score, MulticlassPrecision\n",
    "\n",
    "def compute_dice_coefficient(preds, targets):\n",
    "    \"\"\"\n",
    "    Calcula o coeficiente de Dice\n",
    "    \"\"\"\n",
    "    intersection = (preds * targets).sum()\n",
    "    dice = (2. * intersection) / (preds.sum() + targets.sum())\n",
    "    return dice.item()\n",
    "\n",
    "def compute_aji(preds, targets):\n",
    "    \"\"\"\n",
    "    Calcula o índice de Jaccard agregado (AJI)\n",
    "    \"\"\"\n",
    "    preds = preds.detach().cpu().numpy().astype(np.bool_)\n",
    "    targets = targets.detach().cpu().numpy().astype(np.bool_)\n",
    "    \n",
    "    # Calcula o Jaccard para cada componente individual nos targets/preds\n",
    "    intersection = np.logical_and(preds, targets)\n",
    "    union = np.logical_or(preds, targets)\n",
    "    jaccard_per_class = intersection.sum() / (union.sum() + 1e-10)  # Evitar divisão por zero\n",
    "    return jaccard_per_class\n",
    "\n",
    "# Configurar as métricas, incluindo Dice e AJI personalizados\n",
    "metrics = {\n",
    "    'F1': MulticlassF1Score(num_classes=len(CLASS_COLORS)).to(device),\n",
    "    'Jaccard': MulticlassJaccardIndex(num_classes=len(CLASS_COLORS)).to(device),\n",
    "    'Precision': MulticlassPrecision(num_classes=len(CLASS_COLORS)).to(device),\n",
    "    'Dice': compute_dice_coefficient,\n",
    "    'AJI': compute_aji\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_by_kind(model, n_base=7):\n",
    "    base_vgg_bias = []\n",
    "    base_vgg_weight = []\n",
    "    core_weight = []\n",
    "    core_bias = []\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'vgg' in name and ('weight' in name or 'bias' in name):\n",
    "            vgglayer = int(name.split('.')[-2])\n",
    "\n",
    "            if vgglayer <= n_base:\n",
    "                if 'bias' in name:\n",
    "                    base_vgg_bias.append(param)\n",
    "                else:\n",
    "                    base_vgg_weight.append(param)\n",
    "            else:\n",
    "                if 'bias' in name:\n",
    "                    core_bias.append(param)\n",
    "                else:\n",
    "                    core_weight.append(param)\n",
    "        elif ('weight' in name or 'bias' in name):\n",
    "            if 'bias' in name:\n",
    "                core_bias.append(param)\n",
    "            else:\n",
    "                core_weight.append(param)\n",
    "\n",
    "    return base_vgg_weight, base_vgg_bias, core_weight, core_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import os\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuração do diretório para salvar os resultados\n",
    "results_dir = \"E:/Mestrado/Materias/2024-02-Sistemas para Processamento Multimidia/seminario/image-segmentation/results/data\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "def train_model_with_early_stopping(model, train_loader, val_loader, criterion, optimizer, metrics, num_epochs, device, patience, model_name, results_dir):\n",
    "    since = time.time()\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    epochs_run = 0  # Variável para contar as épocas realizadas\n",
    "\n",
    "    # Variáveis para armazenar tempos de execução\n",
    "    training_time = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        epochs_run += 1  # Registrar a execução da época\n",
    "\n",
    "        epoch_start = time.time()  # Marcar o início da época\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                data_loader = train_loader\n",
    "            else:\n",
    "                model.eval()\n",
    "                data_loader = val_loader\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_metrics = {key: 0 for key in metrics.keys()}\n",
    "            \n",
    "            for inputs, masks in tqdm(data_loader):\n",
    "                inputs, masks = inputs.to(device), masks.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, masks)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                for metric_name, metric in metrics.items():\n",
    "                    if metric_name in ['Dice', 'AJI']:\n",
    "                        value = metric(preds, masks)\n",
    "                    else:  # Para métricas torchmetrics\n",
    "                        value = metric(preds, masks).item()\n",
    "                    running_metrics[metric_name] += value * inputs.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / len(data_loader.dataset)\n",
    "            epoch_metrics = {key: value / len(data_loader.dataset) for key, value in running_metrics.items()}\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f}')\n",
    "            for metric_name in metrics:\n",
    "                print(f'{phase} {metric_name}: {epoch_metrics[metric_name]:.4f}')\n",
    "\n",
    "            if phase == 'val':\n",
    "                if epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = model.state_dict()\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "\n",
    "        epoch_end = time.time()  # Marcar o fim da época\n",
    "        epoch_time = epoch_end - epoch_start\n",
    "        training_time += epoch_time  # Acumular tempos totais\n",
    "        print(f'Epoch time: {epoch_time:.2f} seconds')\n",
    "\n",
    "        print(f'Patience counter: {patience_counter}')\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val loss: {best_loss:.4f}')\n",
    "    print(f'Total epochs run: {epochs_run}')\n",
    "\n",
    "    # Restaurar o melhor modelo\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    # Salvar o modelo treinado\n",
    "    model_path = os.path.join(results_dir, f'{model_name}_best.pth')\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    # Coletar as métricas finais\n",
    "    final_metrics = epoch_metrics\n",
    "    final_metrics['best_loss'] = best_loss\n",
    "    final_metrics['training_time'] = time_elapsed\n",
    "    final_metrics['epochs_run'] = epochs_run\n",
    "\n",
    "    # Salvar todas as métricas para CSV\n",
    "    csv_path = os.path.join(results_dir, 'results.csv')\n",
    "    write_metrics_to_csv(csv_path, model_name, final_metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "def write_metrics_to_csv(csv_path, model_name, metrics):\n",
    "    headers = ['nome', 'f1-score', 'indice jaccard', 'precision', 'dice', 'aji', 'best_loss', 'training_time', 'epochs_run']\n",
    "    row = [\n",
    "        model_name,\n",
    "        metrics['F1'],\n",
    "        metrics['Jaccard'],\n",
    "        metrics['Precision'],\n",
    "        metrics['Dice'],\n",
    "        metrics['AJI'],\n",
    "        metrics['best_loss'],\n",
    "        metrics['training_time'],\n",
    "        metrics['epochs_run']\n",
    "    ]\n",
    "\n",
    "    file_exists = os.path.isfile(csv_path)\n",
    "\n",
    "    with open(csv_path, mode='a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if not file_exists:\n",
    "            writer.writerow(headers)  # Escrever cabeçalhos se o arquivo não existe\n",
    "        writer.writerow(row)  # Salvar linha de métricas\n",
    "\n",
    "# Executar o Treinamento dos Modelos\n",
    "for model_name, model in models.items():\n",
    "    print(\"*********************************************************************\")\n",
    "    print(f\"Treinando {model_name} com early stopping.\")\n",
    "    \n",
    "    # Defina os grupos de parâmetros para o modelo atual\n",
    "    base_vgg_weight, base_vgg_bias, core_weight, core_bias = get_params_by_kind(model, 7)\n",
    "\n",
    "    # Configurar o otimizador com diferentes learning rates para cada grupo de parâmetros\n",
    "    optimizer = torch.optim.SGD([\n",
    "        {'params': base_vgg_bias, 'lr': 0.00001},\n",
    "        {'params': base_vgg_weight, 'lr': 0.00001},\n",
    "        {'params': core_bias, 'lr': 0.02},\n",
    "        {'params': core_weight, 'lr': 0.02, 'weight_decay': 0.0005}\n",
    "    ], momentum=0.9)\n",
    "\n",
    "    # Treinando o modelo\n",
    "    trained_model = train_model_with_early_stopping(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        metrics=metrics,\n",
    "        num_epochs=num_epochs,\n",
    "        device=device,\n",
    "        patience=patience,\n",
    "        model_name=model_name,\n",
    "        results_dir=results_dir\n",
    "    )\n",
    "    print(f'{model_name} treinado e salvo com sucesso.')\n",
    "\n",
    "print(\"Treinamento completo de todos os modelos com early stopping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Diretório para salvar os resultados das imagens\n",
    "results_dir = \"E:/Mestrado/Materias/2024-02-Sistemas para Processamento Multimidia/seminario/image-segmentation/results/images\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Diretório onde os arquivos do modelo foram salvados\n",
    "model_dir = \"E:/Mestrado/Materias/2024-02-Sistemas para Processamento Multimidia/seminario/image-segmentation/results/data\" \n",
    "\n",
    "# Função auxiliar para transformar índices de classe em cores RGB\n",
    "def class_to_rgb(mask_indices):\n",
    "    mask_rgb = np.zeros((mask_indices.shape[0], mask_indices.shape[1], 3), dtype=np.uint8)\n",
    "    unique_classes = np.unique(mask_indices)\n",
    "    print(f\"Unique classes in mask: {unique_classes}\")  # Log para classes únicas\n",
    "\n",
    "    for class_index, color in enumerate(CLASS_COLORS.values()):\n",
    "        mask_rgb[mask_indices == class_index] = color\n",
    "        print(f\"Mapping class {class_index} to color {color}\")  # Log para mapeamento\n",
    "    return mask_rgb\n",
    "\n",
    "# Função para visualizar e salvar predições\n",
    "def visualize_and_save_predictions(model, data_loader, device, results_dir, model_name, num_images=5):\n",
    "    model.eval()\n",
    "    images_saved = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, masks in data_loader:\n",
    "            inputs, masks = inputs.to(device), masks.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for i in range(inputs.size(0)):\n",
    "                images_saved += 1\n",
    "                if images_saved > num_images:\n",
    "                    return\n",
    "                \n",
    "                # Processamento para visualização\n",
    "                image = (inputs[i].cpu().permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "                \n",
    "                # Conversão de índices para RGB\n",
    "                mask = class_to_rgb(masks[i].cpu().numpy())\n",
    "                prediction = class_to_rgb(preds[i].cpu().numpy())\n",
    "\n",
    "                # Logs para depuração\n",
    "                print(f\"Input shape: {inputs[i].shape}\")\n",
    "                print(f\"Mask shape: {masks[i].shape}\")\n",
    "                print(f\"Prediction shape: {preds[i].shape}\")\n",
    "\n",
    "                # Visualização\n",
    "                plt.figure(figsize=(15, 5))\n",
    "                \n",
    "                plt.subplot(1, 3, 1)\n",
    "                plt.imshow(image)\n",
    "                plt.title('Imagem Original')\n",
    "\n",
    "                plt.subplot(1, 3, 2)\n",
    "                plt.imshow(mask)\n",
    "                plt.title('Máscara Real')\n",
    "\n",
    "                plt.subplot(1, 3, 3)\n",
    "                plt.imshow(prediction)\n",
    "                plt.title('Predição')\n",
    "\n",
    "                plt.show()\n",
    "                \n",
    "                # Salvar as imagens\n",
    "                plt.imsave(os.path.join(results_dir, f'{model_name}_input_{images_saved}.png'), image)\n",
    "                plt.imsave(os.path.join(results_dir, f'{model_name}_mask_{images_saved}.png'), mask)\n",
    "                plt.imsave(os.path.join(results_dir, f'{model_name}_prediction_{images_saved}.png'), prediction)\n",
    "\n",
    "# Executar para cada modelo\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Visualizando e salvando predições para {model_name}...\")\n",
    "    \n",
    "    trained_model = model\n",
    "    trained_model_path = os.path.join(model_dir, f'{model_name}_best.pth')\n",
    "    trained_model.load_state_dict(torch.load(trained_model_path))\n",
    "    trained_model.to(device)\n",
    "    \n",
    "    visualize_and_save_predictions(trained_model, test_loader, device, results_dir, model_name, num_images=5)\n",
    "\n",
    "print(\"Visualização e salvamento concluídos!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
