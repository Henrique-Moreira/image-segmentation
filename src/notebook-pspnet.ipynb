{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guia de Estudo: Compreendendo o Código PSPNet\n",
    "\n",
    "## Questionário\n",
    "1) Qual é a função do arquivo data_utils.py no contexto do projeto PSPNet?\n",
    "2) Descreva o propósito do arquivo inference_sample.py e como ele se relaciona com o modelo PSPNet treinado.\n",
    "3) Explique a estrutura e funcionalidade da rede PSPNet implementada em psp_net.py.\n",
    "4) Quais são os principais argumentos e opções de configuração disponíveis no script train_psp.py?\n",
    "5) Como o processo de treinamento é realizado usando o script train_psp.py?\n",
    "6) Descreva a importância do módulo Pyramid Pooling Module na arquitetura PSPNet.\n",
    "7) Que tipos de dados de entrada e saída são esperados pelos scripts inference_sample.py e train_psp.py?\n",
    "8) Com quais outras bibliotecas ou frameworks o código PSPNet provavelmente interage e por quê?\n",
    "9) Quais métricas de avaliação você usaria para medir o desempenho do modelo PSPNet?\n",
    "10) Como o código pode ser modificado para incorporar novos conjuntos de dados ou diferentes tarefas de segmentação semântica?\n",
    "\n",
    "## Gabarito\n",
    "- O arquivo data_utils.py contém funções utilitárias para lidar com dados, como carregamento, pré-processamento e aumento de dados para o treinamento do modelo PSPNet.\n",
    "- O arquivo inference_sample.py permite realizar inferência com um modelo PSPNet treinado. Ele carrega o modelo, processa uma imagem de entrada e gera uma previsão de segmentação semântica.\n",
    "- O arquivo psp_net.py define a arquitetura da rede PSPNet, incluindo a estrutura principal da rede, o módulo Pyramid Pooling e as camadas de saída. Ele implementa a lógica para propagação direta e cálculo de perdas.\n",
    "- O script train_psp.py possui argumentos para configurar o processo de treinamento, como a taxa de aprendizado, o tamanho do lote, o número de épocas, o caminho para os dados de treinamento e o modelo pré-treinado.\n",
    "- O script train_psp.py carrega os dados de treinamento, instancia o modelo PSPNet, define o otimizador e a função de perda, e executa o loop de treinamento, atualizando os pesos do modelo a cada época.\n",
    "- O Pyramid Pooling Module captura informações contextuais de múltiplas escalas, agregando recursos em diferentes níveis de resolução, o que melhora a capacidade do modelo de segmentar objetos de tamanhos variados.\n",
    "- Os scripts inference_sample.py e train_psp.py esperam imagens como entrada e produzem mapas de segmentação semântica como saída, onde cada pixel é atribuído a uma classe.\n",
    "- O código PSPNet provavelmente interage com bibliotecas como TensorFlow ou PyTorch para operações de tensores e treinamento de redes neurais, OpenCV para processamento de imagens e NumPy para manipulação de matrizes.\n",
    "- Métricas como precisão de pixel, Intersection over Union (IoU) e Dice coefficient são usadas para avaliar o desempenho de modelos de segmentação semântica como o PSPNet.\n",
    "- Para incorporar novos conjuntos de dados ou tarefas, o código pode ser modificado ajustando as funções de carregamento de dados em data_utils.py, definindo novas classes de saída em psp_net.py e adaptando a lógica de treinamento em train_psp.py.\n",
    "\n",
    "## Questões Dissertativas\n",
    "- Compare e contraste a arquitetura PSPNet com outras arquiteturas de segmentação semântica, como FCN e U-Net. Destaque as principais diferenças em suas estruturas e como elas afetam o desempenho.\n",
    "- Explique em detalhes como o Pyramid Pooling Module na PSPNet contribui para capturar informações contextuais multi-escala. Discuta os benefícios de usar esse módulo em tarefas de segmentação semântica.\n",
    "- Analise o processo de treinamento do PSPNet implementado em train_psp.py. Descreva os diferentes estágios do treinamento, os hiperparâmetros envolvidos e as estratégias para otimizar o desempenho do modelo.\n",
    "- Discuta os desafios e limitações do modelo PSPNet em cenários do mundo real. Explore as áreas potenciais para melhorias e como o código pode ser adaptado para lidar com esses desafios.\n",
    "- Investigue aplicações práticas da segmentação semântica usando PSPNet em domínios como condução autônoma, análise de imagens médicas ou detecção de objetos. Forneça exemplos específicos e discuta o impacto da PSPNet nesses campos.\n",
    "\n",
    "## Glossário\n",
    "- Termo Definição Segmentação: Semântica Tarefa de visão computacional que visa atribuir um rótulo de classe a cada pixel em uma imagem.\n",
    "- PSPNet: Arquitetura de rede neural profunda para segmentação semântica, conhecida por sua capacidade de capturar informações contextuais multi-escala.\n",
    "- Pyramid Pooling Module: Módulo chave na PSPNet que agrega recursos em diferentes níveis de resolução para obter representações contextuais.\n",
    "- Inferência: Processo de usar um modelo treinado para fazer previsões sobre novos dados.\n",
    "- Treinamento: Processo de ajustar os pesos de um modelo neural para minimizar a diferença entre as previsões e os rótulos reais.\n",
    "- Época: Uma passagem completa por todo o conjunto de dados de treinamento durante o processo de treinamento.\n",
    "- Taxa de Aprendizado: Hiperparâmetro que controla o tamanho da etapa na atualização dos pesos do modelo durante o treinamento.\n",
    "- Tamanho do Lote: Número de amostras de dados processadas em uma única iteração durante o treinamento.\n",
    "- IoU (Intersection over Union): Métrica de avaliação para segmentação semântica que mede a sobreposição entre a previsão e o rótulo real.\n",
    "- Precisão de Pixel: Métrica de avaliação que calcula a porcentagem de pixels corretamente classificados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalação de Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install torch\n",
    "%pip install torchvision\n",
    "%pip install utils2\n",
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas Importadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import utils2\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from math import sqrt\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaração de Variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA:\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Caminho do diretório Dataset:\n",
    "directory = os.path.abspath(os.path.join(os.getcwd(), '..')) + r'\\Dataset\\nematode-detection-labels'\n",
    "print(f'Diretório do Projeto {directory}.')\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "img_folder_val = directory + r'\\Val'\n",
    "img_folder_train = directory + r'\\Train'\n",
    "img_folder_test = directory + r'\\Test'\n",
    "save_dir = directory + r'\\\\result_psp\\\\'\n",
    "if not os.path.exists(img_folder_val):\n",
    "    os.makedirs(img_folder_val)\n",
    "if not os.path.exists(img_folder_train):\n",
    "    os.makedirs(img_folder_train)\n",
    "if not os.path.exists(img_folder_test):\n",
    "    os.makedirs(img_folder_test)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "model_file_name = 'model_psp.pth'\n",
    "\n",
    "# size mismatch (got input: [1, 3, 480, 640] , target: [1, 960, 1280]\n",
    "resolution_input = (640, 480) # Size Out (1280, 960)\n",
    "\n",
    "patience = 30\n",
    "plot_val = True\n",
    "plot_train = True\n",
    "\n",
    "max_epochs = 100\n",
    "\n",
    "class_weights = [1, 1, 1]\n",
    "nClasses = 3\n",
    "\n",
    "class_to_color = {'Ground': (127, 0, 0) , 'Healthy': (0, 127, 127), 'Pest': (0, 255, 0)}\n",
    "class_to_id = {'Ground': 0, 'Healthy': 1, 'Pest': 2}\n",
    "id_to_class = {v: k for k, v in class_to_id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a classe de Segmentation do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    \"\"\"Segmentation dataset loader.\"\"\"\n",
    "\n",
    "    def __init__(self, json_folder, img_folder, is_train, class_to_id, resolution_input = (640, 480), augmentation = False, transform=None):\n",
    "    #def __init__(self, json_folder, img_folder, is_train, class_to_id, resolution_input = (1280, 960), augmentation = False, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            json_folder (str): Path to folder that contains the annotations.\n",
    "            img_folder (str): Path to all images.\n",
    "            is_train (bool): Is this a training dataset ?\n",
    "            augmentation (bool): Do dataset augmentation (crete artificial variance) ?\n",
    "        \"\"\"\n",
    "\n",
    "        self.gt_file_list = glob.glob(osp.join(json_folder, '*.json'))\n",
    "\n",
    "        self.total_samples = len(self.gt_file_list)\n",
    "        self.img_folder = img_folder\n",
    "        self.is_train = is_train\n",
    "        self.transform = transform\n",
    "        self.augmentation = augmentation\n",
    "        self.resolution = resolution_input\n",
    "        self.class_to_id = class_to_id\n",
    "        \n",
    "        \n",
    "        # Mean and std are needed because we start from a pre trained net\n",
    "        self.mean = [0.485, 0.456, 0.406]\n",
    "        self.std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        gt_file = self.gt_file_list[idx]\n",
    "        img_number_str = gt_file.split('.')[0].split('/')[-1]\n",
    "\t# Abre Json\n",
    "        gt_json = json.load(open(gt_file, 'r'))\n",
    "\t# Abre imagem\n",
    "        img_np = cv2.imread(osp.join(self.img_folder, img_number_str + '.png'), cv2.IMREAD_IGNORE_ORIENTATION + cv2.IMREAD_COLOR)\n",
    "        original_shape = img_np.shape\n",
    "        img_np = cv2.resize(img_np, (self.resolution[0], self.resolution[1]))[..., ::-1]\n",
    "        img_np = np.ascontiguousarray(img_np)\n",
    "\t# Cria imagem zerada\n",
    "        label_np = np.zeros((img_np.shape[0], img_np.shape[1]))\n",
    "        label_np[...] = -1\n",
    "        \n",
    "\t# Para todos poligonos\n",
    "        for shape in gt_json['shapes']:\n",
    "            # Transforma os pontos do poligono em array\n",
    "            points_np = np.array(shape['points'], dtype = np.float64)\n",
    "\n",
    "\t    # Ajusta os pontos porque eu mudo o resolucao (pode ignorar)\n",
    "            points_np[:, 0] *= self.resolution[0]/original_shape[1]\n",
    "            points_np[:, 1] *= self.resolution[1]/original_shape[0]\n",
    "\t    # As coordenadas dos pontos que formam o poligono tem que ser inteiros\n",
    "            points_np = np.round(points_np).astype(np.int64)\n",
    "\t    # Coloca os pontos no formato certo para o opencv\n",
    "            points_np = points_np.reshape((-1,1,2))\n",
    "\t    # Pinta o poligono usando o opencv com o valor referente ao label\n",
    "            label_np = cv2.fillPoly(label_np, [points_np], self.class_to_id[shape['label']])\n",
    "\n",
    "        # Transforma o GT em inteiro    \n",
    "        label_np = label_np.astype(np.int32)\n",
    "        \n",
    "        if self.is_train and self.augmentation:\n",
    "            if np.random.rand() > 0.5:\n",
    "                img_np = np.fliplr(img_np)\n",
    "                label_np = np.fliplr(label_np)\n",
    "                img_np = np.ascontiguousarray(img_np)\n",
    "                label_np = np.ascontiguousarray(label_np)\n",
    "        \n",
    "        img_pt = img_np.astype(np.float32) / 255.0\n",
    "        for i in range(3):\n",
    "            img_pt[..., i] -= self.mean[i]\n",
    "            img_pt[..., i] /= self.std[i]\n",
    "            \n",
    "        img_pt = img_pt.transpose(2,0,1)\n",
    "            \n",
    "        img_pt = torch.from_numpy(img_pt)\n",
    "        label_pt = torch.from_numpy(label_np).long()\n",
    "        #print(img_number_str, img_pt.shape)\n",
    "\n",
    "        sample = {'image': img_pt, 'gt': label_pt, 'image_original': img_np}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a Classe da Rede PSPDec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPDec(torch.nn.Module):\n",
    "\tdef __init__(self, in_dim, reduction_dim, setting):\n",
    "\t\tsuper(PSPDec, self).__init__()\n",
    "\t\tself.features = []\n",
    "\t\tfor s in setting:\n",
    "\t\t\tself.features.append(torch.nn.Sequential(\n",
    "\t\t\t\ttorch.nn.AdaptiveAvgPool2d(s),\n",
    "\t\t\t\ttorch.nn.Conv2d(in_dim, reduction_dim, kernel_size=1, bias=False),\n",
    "\t\t\t\t#torch.nn.BatchNorm2d(reduction_dim, momentum=.95),\n",
    "\t\t\t\t#torch.nn.InstanceNorm2d(reduction_dim, momentum=.95),\n",
    "\t\t\t\ttorch.nn.ReLU(inplace=True)\n",
    "\t\t\t))\n",
    "\t\tself.features = torch.nn.ModuleList(self.features)\n",
    "\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx_size = x.size()\n",
    "\t\tout = [x]\n",
    "\t\tfor f in self.features:\n",
    "\t\t\tout.append(torch.nn.functional.upsample(f(x), x_size[2:], mode='bilinear'))\n",
    "\t\tout = torch.cat(out, 1)\n",
    "\t\treturn out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a Classe da Rede PSPNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPNet(torch.nn.Module):\n",
    "\n",
    "\tdef __init__(self, num_classes):\n",
    "\t\tsuper(PSPNet, self).__init__()\n",
    "\n",
    "\t\tresnet = torchvision.models.resnet101(pretrained=True)\n",
    "\t\t#print('resnet', resnet)\n",
    "\n",
    "\t\tself.layer0 = torch.nn.Sequential(\n",
    "\t\t\tresnet.conv1,\n",
    "\t\t\tresnet.bn1,\n",
    "\t\t\tresnet.relu,\n",
    "\t\t\tresnet.maxpool\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tself.layer1 = resnet.layer1\n",
    "\t\tself.layer2 = resnet.layer2\n",
    "\t\tself.layer3 = resnet.layer3\n",
    "\t\tself.layer4 = resnet.layer4\n",
    "\t\t\n",
    "\n",
    "\t\tfor n, m in self.layer3.named_modules():\n",
    "\t\t\tif 'conv2' in n:\n",
    "\t\t\t\tm.dilation, m.padding, m.stride = (2, 2), (2, 2), (1, 1)\n",
    "\t\t\telif 'downsample.0' in n:\n",
    "\t\t\t\tm.stride = (1, 1)\n",
    "\t\tfor n, m in self.layer4.named_modules():\n",
    "\t\t\tif 'conv2' in n:\n",
    "\t\t\t\tm.dilation, m.padding, m.stride = (4, 4), (4, 4), (1, 1)\n",
    "\t\t\telif 'downsample.0' in n:\n",
    "\t\t\t\tm.stride = (1, 1)\n",
    "\n",
    "\n",
    "\t\tself.ppm = PSPDec(2048, 512, (1, 2, 3, 6))\n",
    "\n",
    "\t\tself.final = torch.nn.Sequential(\n",
    "\t\t\ttorch.nn.Conv2d(4096, 512, 3, padding=1, bias=False),\n",
    "\t\t\ttorch.nn.BatchNorm2d(512, momentum=.95),\n",
    "\t\t\ttorch.nn.ReLU(inplace=True),\n",
    "\t\t\ttorch.nn.Dropout(.1),\n",
    "\t\t\ttorch.nn.Conv2d(512, num_classes, 1),\n",
    "\t\t)\n",
    "\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.layer0(x)\n",
    "\t\tx = self.layer1(x)\n",
    "\t\tx = self.layer2(x)\n",
    "\t\tx = self.layer3(x)\n",
    "\t\tx = self.layer4(x)\n",
    "\t\t\n",
    "\t\tx = self.ppm(x)\n",
    "\t\tx = self.final(x)\n",
    "\t\treturn torch.nn.functional.upsample(x, (480, 640), mode='bilinear')\n",
    "\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef eval_net_with_loss(model, inp, gt, class_weights, device):\n",
    "\n",
    "\t\tweights = torch.from_numpy(np.array(class_weights, dtype=np.float32)).to(device)\n",
    "\t\tout = model(inp)\n",
    "\n",
    "\t\tsoftmax = torch.nn.functional.log_softmax(out, dim = 1)\n",
    "\t\tloss = torch.nn.functional.nll_loss(softmax, gt, ignore_index=-1, weight=weights)\n",
    "\n",
    "\t\treturn (out, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realiza o Treinamento da Rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SegmentationDataset(img_folder_train, img_folder_train, True, class_to_id, resolution_input, True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=0, drop_last=False)\n",
    "\n",
    "val_dataset = SegmentationDataset(img_folder_val, img_folder_val, False, class_to_id, resolution_input)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True, num_workers=0, drop_last=False)\n",
    "\n",
    "\n",
    "if plot_train:\n",
    "\n",
    "    for i_batch, sample_batched in enumerate(train_loader):\n",
    "    \n",
    "            image_np = np.squeeze(sample_batched['image_original'].cpu().numpy())\n",
    "            gt = np.squeeze(sample_batched['gt'].cpu().numpy())\n",
    "                \n",
    "            color_label = np.zeros((resolution_input[1], resolution_input[0], 3))\n",
    "            \n",
    "            for key, val in id_to_class.items():\n",
    "                color_label[gt == key] = class_to_color[val]\n",
    "                \n",
    "            plt.figure()\n",
    "            plt.imshow((image_np/255) * 0.5 + (color_label/255) * 0.5)\n",
    "            plt.show()\n",
    "            \n",
    "            plt.figure()\n",
    "            plt.imshow(color_label.astype(np.uint8))\n",
    "            plt.show()\n",
    "\n",
    "model = PSPNet(nClasses).to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), 1e-2, .9, 1e-4)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 30, gamma=0.2)\n",
    "\n",
    "best_val_acc = -1\n",
    "best_epoch = 0\n",
    "\n",
    "# Start training...\n",
    "for epoch in range(max_epochs):\n",
    "    print('Epoch %d starting...' % (epoch+1))\n",
    "\n",
    "    lr_scheduler.step()\n",
    "    model.train()\n",
    "\n",
    "    mean_loss = 0.0\n",
    "    n_correct = 0\n",
    "    n_false = 0\n",
    "\n",
    "    for i_batch, sample_batched in enumerate(train_loader):\n",
    "        image = sample_batched['image'].to(device)\n",
    "        gt = sample_batched['gt'].to(device)\n",
    "        '''\n",
    "        inputs = Variable(image)\n",
    "        print('inputs', inputs.size())\n",
    "\n",
    "        outputs = model(image)\n",
    "        optimizer.zero_grad()\n",
    "        '''\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        #out, aux = model(image)\n",
    "        #out = model(image)\n",
    "        output, total_loss = model.eval_net_with_loss(model, image, gt, class_weights, device)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        mean_loss += total_loss.cpu().detach().numpy()\n",
    "\n",
    "        # Measure accuracy\n",
    "        \n",
    "        gt = np.squeeze(sample_batched['gt'].cpu().numpy())\n",
    "        \n",
    "        label_out = torch.nn.functional.softmax(output, dim = 1)\n",
    "        label_out = label_out.cpu().detach().numpy()\n",
    "        label_out = np.squeeze(label_out)\n",
    "        \n",
    "        labels = np.argmax(label_out, axis=0)\n",
    "        valid_mask = gt != -1\n",
    "        curr_correct = np.sum(gt[valid_mask] == labels[valid_mask])\n",
    "        curr_false = np.sum(valid_mask) - curr_correct\n",
    "        n_correct += curr_correct\n",
    "        n_false += curr_false\n",
    "\n",
    "    mean_loss /= len(train_loader)\n",
    "    train_acc = n_correct / (n_correct + n_false)\n",
    "\n",
    "    print('Train loss: %f, train acc: %f' % (mean_loss, train_acc))\n",
    "\n",
    "    n_correct = 0\n",
    "    n_false = 0\n",
    "\n",
    "    for i_batch, sample_batched in enumerate(val_loader):\n",
    "\n",
    "        image = sample_batched['image'].to(device)\n",
    "        image_np = np.squeeze(sample_batched['image_original'].cpu().numpy())\n",
    "        gt = np.squeeze(sample_batched['gt'].cpu().numpy())\n",
    "        \n",
    "    \n",
    "        label_out = model(image)\n",
    "        label_out = torch.nn.functional.softmax(label_out, dim = 1)\n",
    "        label_out = label_out.cpu().detach().numpy()\n",
    "        label_out = np.squeeze(label_out)\n",
    "\n",
    "        labels = np.argmax(label_out, axis=0)\n",
    "\n",
    "        if plot_val:\n",
    "            color_label = np.zeros((resolution_input[1], resolution_input[0], 3))\n",
    "\n",
    "            for key, val in id_to_class.items():\n",
    "                color_label[labels == key] = class_to_color[val]\n",
    "                \n",
    "            plt.figure()\n",
    "            plt.imshow((image_np/255) * 0.5 + (color_label/255) * 0.5)\n",
    "            plt.show()\n",
    "            \n",
    "            plt.figure()\n",
    "            plt.imshow(color_label.astype(np.uint8))\n",
    "            plt.show()\n",
    "\n",
    "        valid_mask = gt != -1\n",
    "        curr_correct = np.sum(gt[valid_mask] == labels[valid_mask])\n",
    "        curr_false = np.sum(valid_mask) - curr_correct\n",
    "        n_correct += curr_correct\n",
    "        n_false += curr_false\n",
    "\n",
    "    total_acc = n_correct / (n_correct + n_false)\n",
    "\n",
    "    if best_val_acc < total_acc:\n",
    "        best_val_acc = total_acc\n",
    "        if epoch > 7:\n",
    "            torch.save(model.state_dict(), model_file_name)\n",
    "            print('New best validation acc. Saving...')\n",
    "        best_epoch = epoch\n",
    "\n",
    "    if (epoch - best_epoch) > patience:\n",
    "        print(\"Fnishing training, best validation acc %f\", best_val_acc)\n",
    "        break\n",
    "\n",
    "    print('Val acc: %f -- Best val acc: %f -- epoch %d.' % (total_acc, best_val_acc, best_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferência de dados\n",
    "Processo de usar um modelo treinado para fazer previsões sobre novos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color in RGB\n",
    "class_to_color = {'Ground': (127, 0, 0) , 'Healthy': (0, 127, 127), 'Pest': (0, 255, 0)}\n",
    "class_to_id = {'Ground': 0, 'Healthy': 1, 'Pest': 2}\n",
    "id_to_class = {v: k for k, v in class_to_id.items()}\n",
    "nClasses = 3\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "model = PSPNet(nClasses)\n",
    "model.load_state_dict(torch.load(model_file_name))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "img_list = glob.glob(osp.join(img_folder_val, '*.png'))\n",
    "\n",
    "for img_path in img_list:\n",
    "\n",
    "        img_np = cv2.imread(img_path, cv2.IMREAD_IGNORE_ORIENTATION + cv2.IMREAD_COLOR)\n",
    "        img_np = cv2.resize(img_np, (resolution_input[0], resolution_input[1]))[..., ::-1]\n",
    "        img_np = np.ascontiguousarray(img_np)\n",
    "        \n",
    "        img_pt = np.copy(img_np).astype(np.float32) / 255.0\n",
    "        for i in range(3):\n",
    "            img_pt[..., i] -= mean[i]\n",
    "            img_pt[..., i] /= std[i]\n",
    "            \n",
    "        img_pt = img_pt.transpose(2,0,1)\n",
    "            \n",
    "        img_pt = torch.from_numpy(img_pt[None, ...]).to(device)\n",
    "        \n",
    "        label_out = model(img_pt)\n",
    "        label_out = torch.nn.functional.softmax(label_out, dim = 1)\n",
    "        label_out = label_out.cpu().detach().numpy()\n",
    "        label_out = np.squeeze(label_out)\n",
    "        \n",
    "        labels = np.argmax(label_out, axis=0)\n",
    "        \n",
    "        color_label = np.zeros((resolution_input[1], resolution_input[0], 3))\n",
    "            \n",
    "        for key, val in id_to_class.items():\n",
    "            color_label[labels == key] = class_to_color[val]\n",
    "            \n",
    "        plt.figure()\n",
    "        plt.imshow((img_np/255) * 0.5 + (color_label/255) * 0.5)\n",
    "        plt.savefig(save_dir + \"IMG\" + \".png\")\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.imshow(color_label.astype(np.uint8))\n",
    "        plt.savefig(save_dir + \"GT\" + \".png\")\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
